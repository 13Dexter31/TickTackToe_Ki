{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 QNN (Q-Wertbasiertes Neuronales Netzwerk)\n",
    "\n",
    "Für die Erweiterbarkeit unseres Codes ist uns aufgefallen, dass der Q-Algorithmus seine Grenzen bei Spielen mit einem beinahe unendlichen Zustandsraum aufweist. Spiele wie Schach oder Go haben einen derart riesigen Zustandsraum aller möglichen Züge, der ohne weitere Hilfe nicht einfach durch ausprobieren komplett erkundet werden kann. Um dem Prinzip des bestärkenden Lernens nahe zu kommen, müssen andere Methoden gefunden werden, um zukünftige Züge oder sogar Strategien bei unendlich wirkenden Zustandsräumen hervorzusagen. Hierfür soll ein neuronales Netzwerk mit mehreren Schichten zum Einsatz kommen.\n",
    "\n",
    "Der Gedanke dahinter ist, dass man nicht mehr versucht alle Zustände zu erkunden und perfekt vorherzusagen, sondern eine Struktur oder sogar Strategie in gewissen Zügen zu erkennen. Der Fokus des neuronalen Netzes soll damit sein, Strukturen in zeitlich aufeinanderfolgender Züge zu erkennen und bei unbekannten Zuständen einen Schätzwert auf Basis bisher bekannter Strategien ausgeben.\n",
    "\n",
    "Ein neuronales Netzwerk besteht zumeist aus Eingabevektoren, verschiedenste versteckte Schichten sowie Ausgabevektoren. Genauso wie die Q-Funktion, sollen dem QNN gewisse Parameter als Eingabevektoren mitgegeben werden. Dazu gehört der aktuelle Zustand des Bretts, die ausgewählte Aktion auf Basis vorheriger Werte aus dem QNN Modell und ggf. die Belohnung. Als Ausgabevektor soll, genauso wie bei der Q-Funktion, ein Q-Wert sein, der die maximale Belohnung des aktuellen Zustand-Aktion-Paares beschreibt.\n",
    "\n",
    "Die Lerndaten erstellt der QNN Agent selbst, durch das explorative Erkunden mittels dem Explorationsfaktor namens \"Theta\". Anhand der explorierten Daten und erlangten Belohnungen wird das QNN selbst die besten Züge herausfinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from pathlib import Path\n",
    "from build.player.QPlayer import QPlayer\n",
    "from build.player.qlearner.QLearner import QLearner\n",
    "from build.Board import Board\n",
    "\n",
    "import numpy as np\n",
    "import keras.models as Km\n",
    "import keras.layers as kl\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QNNLearner(QLearner):\n",
    "    \"\"\"\n",
    "    QLearner specification for neural network learning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model = None, learn_rate=0.1, discount_factor=0.8, batch_size=10):\n",
    "        \"\"\"\n",
    "        :param model: used qnn model structure\n",
    "        :param learn_rate: learning rate of this q learner\n",
    "        :param discount_factor: discount factor of this q learner\n",
    "        \"\"\"\n",
    "        self.possible_actions = {0:[1, 1], 1:[2, 1], 2:[3, 1], 3:[1, 2], 4:[2, 2], 5:[3, 2], 6:[1, 3], 7:[2, 3], 8:[3, 3]}\n",
    "        self.learn_rate = learn_rate\n",
    "        self.model = model\n",
    "        self.discount_factor = discount_factor\n",
    "        self.memory = []\n",
    "        self.count_memory = 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def update(self, prev_state, state, prev_move, reward):\n",
    "        \"\"\"\n",
    "        Update q players knowledge by learning offline or online\n",
    "        :param prev_state: previous known state\n",
    "        :param state: new state\n",
    "        :param prev_move: previous made move\n",
    "        :param reward: previous reward\n",
    "        \"\"\"\n",
    "        self.load_to_memory(prev_state, prev_move, state, reward)\n",
    "\n",
    "        self.count_memory += 1\n",
    "\n",
    "        #print(self.count_memory)\n",
    "        if self.count_memory == self.batch_size:\n",
    "            self.count_memory = 0\n",
    "            # Offline training\n",
    "            self.model.learn_batch(self.memory)\n",
    "            # Online training\n",
    "            #self.learn(self.prev_state, self.prev_move, state,  -1, self.reward)\n",
    "            self.memory = []\n",
    "\n",
    "\n",
    "    def load_to_memory(self, prev_state, prev_move, state, reward):\n",
    "        \"\"\"\n",
    "        Load all q related things into memory to learn in batch\n",
    "        :param prev_state: previous known state\n",
    "        :param prev_move: previous made move\n",
    "        :param state: new state\n",
    "        :param reward: previous reward\n",
    "        \"\"\"\n",
    "        self.memory.append([prev_state, prev_move, state, reward])\n",
    "\n",
    "    def select_move(self, state, theta=0.1):\n",
    "        \"\"\"\n",
    "        Select the best move or, if exploring, a random move\n",
    "        :param state: current state\n",
    "        :param theta: temperature value (optional)\n",
    "        :return: chosen action\n",
    "        \"\"\"\n",
    "        p = random.uniform(0, 1)\n",
    "\n",
    "        if p > theta:\n",
    "            action = self.choose_optimal_move(state)\n",
    "            #action = self.possible_actions[idx]\n",
    "        else:\n",
    "            action = random.choice(self.possible_actions)\n",
    "\n",
    "        return action # return choosen move\n",
    "\n",
    "\n",
    "    def choose_optimal_move(self, state):\n",
    "        \"\"\"\n",
    "        Choose optimal move based on the calculated and best predicted values of current state.\n",
    "        :param state: current state\n",
    "        :return: best move with highest value (randomly select for equal values)\n",
    "        \"\"\"\n",
    "        v = -float('Inf') # most negative value (negative infinity float)\n",
    "        v_list = [] # list of all calculated values\n",
    "        idx = [] # move index for chosen move\n",
    "        for move in self.possible_actions:\n",
    "            value = self.model.calc_value(state, move)\n",
    "            v_list.append(round(float(value), 5))\n",
    "\n",
    "            if value > v:\n",
    "                v = value\n",
    "                idx = [move]\n",
    "            elif v == value:\n",
    "                idx.append(move)\n",
    "\n",
    "        idx = random.choice(idx)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"\n",
    "    Model class for all 2 player based games with neural network training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tag):\n",
    "        \"\"\"\n",
    "        :param tag: used tag for neural network model (e.g. 1 for first player and -1 for second)\n",
    "        \"\"\"\n",
    "        self.tag = tag\n",
    "        self.epsilon = 0.1\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 1\n",
    "        self.model = self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads previously saved model\n",
    "        :return: loaded model\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        if self.tag == 1:\n",
    "            tag = '_first'\n",
    "        else:\n",
    "            tag = '_second'\n",
    "            \"\"\"\n",
    "       # s = 'model_values' + tag + '.h5'\n",
    "        s = 'model_values.h5'\n",
    "        model_file = Path(s)\n",
    "\n",
    "        if model_file.is_file():\n",
    "            print('load model')\n",
    "            model = Km.load_model(s)\n",
    "            print('load model: ' + s)\n",
    "        else:\n",
    "            model = self.create_model()\n",
    "        return model\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create new model with appropriate number of layers and network structure\n",
    "        :return: created model\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def state_to_tensor(self, state, move):\n",
    "        \"\"\"\n",
    "        Creates a tensor (2 dim array) based on a state and a move as input vector for nn\n",
    "        :param state: current state\n",
    "        :param move: current move\n",
    "        :return: created tensor\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def calc_value(self, state, move):\n",
    "        \"\"\"\n",
    "        Calculate a tensor and predict the reward\n",
    "        :param state: current state\n",
    "        :param move: current move\n",
    "        :return: most predicted value (predicted reward)\n",
    "        \"\"\"\n",
    "        tensor = self.state_to_tensor(state, move)\n",
    "        value = self.model.predict(tensor)\n",
    "        # K.backend.clear_session()\n",
    "        return value\n",
    "\n",
    "    def calc_target(self, prev_state, prev_move, state, reward):\n",
    "        \"\"\"\n",
    "        Calculate the target vector (q value or reward)\n",
    "        :param prev_state: previous state\n",
    "        :param prev_move: previous move\n",
    "        :param state: current state\n",
    "        :param reward: previous reward\n",
    "        :return: calculated target value\n",
    "        \"\"\"\n",
    "\n",
    "        qvalue = self.calc_value(prev_state, prev_move)\n",
    "        v = []\n",
    "        tensor = self.state_to_tensor(prev_state, prev_move)\n",
    "\n",
    "        for move in range(len(tensor[:,0][0])):\n",
    "            v.append(self.calc_value(state, move))\n",
    "\n",
    "        if reward == 0:\n",
    "            v_s_tag = self.gamma * np.max(v)\n",
    "            target = np.array(qvalue + self.alpha * (reward + v_s_tag - qvalue))\n",
    "        else:\n",
    "            # v_s_tag = 0\n",
    "            target = reward\n",
    "\n",
    "        # target = np.array(v_s + self.alpha * (reward + v_s_tag - v_s))\n",
    "\n",
    "        # if self.tag == 1:\n",
    "        #     print('learn general')\n",
    "        #     print(prev_state, prev_move, state, ava_moves, reward)\n",
    "        # print('target: ', target)\n",
    "\n",
    "        return target\n",
    "\n",
    "    def train_model(self, prev_state, prev_move, target, epochs):\n",
    "        \"\"\"\n",
    "        Train the model based on an input tensor\n",
    "        :param prev_state: previous state\n",
    "        :param prev_move: previous move\n",
    "        :param target: calculated q value or reward (target vector)\n",
    "        :param epochs: number of epochs\n",
    "        \"\"\"\n",
    "\n",
    "        tensor = self.state_to_tensor(prev_state, prev_move)\n",
    "\n",
    "        if target is not None:\n",
    "\n",
    "            if self.tag == 1:\n",
    "                print('value before training:', self.model.predict(tensor))\n",
    "            self.model.fit(tensor, target, epochs=epochs, verbose=0)\n",
    "            # K.backend.clear_session()\n",
    "\n",
    "            if self.tag == 1:\n",
    "                print('target:', target)\n",
    "                print('value after training:', self.model.predict(tensor))\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        save model as h5 file\n",
    "        \"\"\"\n",
    "        if self.tag == 1:\n",
    "            tag = '_first'\n",
    "        else:\n",
    "            tag = '_second'\n",
    "        s = 'model_values' + tag + '.h5'\n",
    "\n",
    "        try:\n",
    "            os.remove(s)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.model.save(s)\n",
    "\n",
    "    def learn_batch(self, memory):\n",
    "        \"\"\"\n",
    "        Learn model with a batch of states and actions from memory\n",
    "        :param memory: saved states, actions and rewards\n",
    "        \"\"\"\n",
    "        print('start learning player', self.tag)\n",
    "        print('data length:', len(memory))\n",
    "\n",
    "        # build x_train\n",
    "        ind = 0\n",
    "        #x_train = np.zeros((len(memory), 7, 7, 1))\n",
    "        x_train = np.zeros((len(memory), 2, 9))\n",
    "        for v in memory:\n",
    "            [prev_state, prev_move, _, _] = v\n",
    "            sample = self.state_to_tensor(prev_state, prev_move)\n",
    "            x_train[ind, :, :] = sample\n",
    "            ind += 1\n",
    "\n",
    "        # train with planning\n",
    "        # for i in range(5):\n",
    "        loss = 20\n",
    "        count = 0\n",
    "        while loss > 0.02 and count < 10:\n",
    "            # tic()\n",
    "            y_train = self.create_targets(memory)\n",
    "            # toc()\n",
    "            self.model.fit(x_train, y_train, epochs=5, batch_size=256, verbose=0)\n",
    "            loss = self.model.evaluate(x_train, y_train, batch_size=256, verbose=0)[0]\n",
    "            count += 1\n",
    "            print('planning number:', count, 'loss', loss)\n",
    "\n",
    "        loss = self.model.evaluate(x_train, y_train, batch_size=256, verbose=0)\n",
    "        print('player:', self.tag, loss, 'loops', count)\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def create_targets(self, memory):\n",
    "        \"\"\"\n",
    "        Create target vector for each state-action-pair in memory\n",
    "        :param memory: saved states, actions and rewards\n",
    "        :return: target vector\n",
    "        \"\"\"\n",
    "        y_train_ = np.zeros((len(memory), 1))\n",
    "        count_ = 0\n",
    "        for v_ in memory:\n",
    "            [prev_state_, prev_move_, state_, reward_] = v_\n",
    "            target = self.calc_target(prev_state_, prev_move_, state_, reward_)\n",
    "            y_train_[count_, :] = target\n",
    "            count_ += 1\n",
    "\n",
    "            # print('---------')\n",
    "            # print('player', self.tag)\n",
    "            # print('prev state', prev_state_)\n",
    "            # print('prev move', prev_move_)\n",
    "            # print('state', state_)\n",
    "            # print('ava moves', ava_moves_)\n",
    "            # print('reward', reward_)\n",
    "            # print('target', target)\n",
    "            #\n",
    "            # value = self.calc_value(prev_state_, prev_move_)\n",
    "            # print('value through net', value)\n",
    "            # time.sleep(0.2)\n",
    "\n",
    "        return y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TicTacToeModel(Model):\n",
    "    \"\"\"\n",
    "    Special model for tic tac toe games.\n",
    "\n",
    "    Consists of 2x9 input vector, dense network of 9 layers and a 9 sized target vector.\n",
    "    Input vector consists an array with length 9 for the chosen move and an array for the state.\n",
    "    Target vector consists of 9 sized array for 9 possible rewards (one for each action).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tag):\n",
    "        super().__init__(tag)\n",
    "        pass\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creates keras model\n",
    "        :return: keras model\n",
    "        \"\"\"\n",
    "        print('new model')\n",
    "\n",
    "        #model = km.load_model(\"qnn_model\")\n",
    "\n",
    "        model = Km.Sequential()\n",
    "        model.add(kl.Flatten(input_shape=(2, 9)))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(18))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(9))\n",
    "        model.add(kl.LeakyReLU(alpha=0.3))\n",
    "        model.add(kl.Dense(1, activation='linear'))\n",
    "\n",
    "        # adam = ko.Adam(lr=0.001)\n",
    "\n",
    "        model.compile(optimizer='Adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "        #model.save(\"qnn_model\")\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def state_to_tensor(self, state, move):\n",
    "        \"\"\"\n",
    "        Generates a tensor of state and move index\n",
    "        :param state: current state\n",
    "        :param move: current move\n",
    "        :return: tensor (2 dim array)\n",
    "        \"\"\"\n",
    "\n",
    "        state = np.array(state)\n",
    "        state = state.flatten() # flatten 3x3 matrix because of 1 length input vector for state\n",
    "        state = self.one_hot_encode_state(state)\n",
    "\n",
    "        a = np.zeros(9).astype('float32')\n",
    "        # a = a.astype('float32')\n",
    "        a[move] = 1 # one hot encoding for chosen action (1 for the chosen action an 0 for none)\n",
    "\n",
    "        state = np.asarray(state).astype('float32')\n",
    "        tensor = np.array((a, state))\n",
    "        #print(tensor)\n",
    "        tensor = tensor.reshape((1, 2, 9))\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def one_hot_encode_state(self, state):\n",
    "        \"\"\"\n",
    "        One hot encoding for the state.\n",
    "        Each field input of 3x3 matrix will be displayed with 0 (blank), 1 (player 1), -1 (player 2)\n",
    "        :param state: state to encode\n",
    "        :return: encoded state\n",
    "        \"\"\"\n",
    "        for i in range(len(state)):\n",
    "            if state[i] is None:\n",
    "                state[i] = 0\n",
    "            if state[i] == 'x':\n",
    "                state[i] = 1\n",
    "            if state[i] == 'o':\n",
    "                state[i] = -1\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021F9370EAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "new model\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021F99DF9CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "new model\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021FD56EBCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "new model\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021FE3AF0310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "new model\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021FE9E74040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model = TicTacToeModel(1)\n",
    "value = np.ndarray(shape=[3,3])\n",
    "pstate = np.ndarray(shape=[3,3])\n",
    "state = [-1,0,-1,0,1,0,0,1,0]\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    tensor = model.state_to_tensor(state, i)\n",
    "    km = model.load_model()\n",
    "    #print(tensor)\n",
    "    value[int(i/3)][i%3] = km.predict(tensor)\n",
    "    pstate[int(i/3)][i%3] = state[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.004319   -0.05889302  0.0786997 ]\n",
      " [-0.02056507  0.11485811  0.00638656]\n",
      " [-0.02371169 -0.01418965  0.00853384]]\n",
      "[[-1.  0. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]]\n",
      "Optimal: 4\n",
      "[[-1.  0. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    pstate[int(i/3)][i%3] = state[i]\n",
    "print(value)\n",
    "print(pstate)\n",
    "print(f\"Optimal: {np.argmax(value)}\")\n",
    "newstate = pstate\n",
    "newstate[int(np.argmax(value)/3)][np.argmax(value)%3] = 1\n",
    "print(newstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from build.Game import Game\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4959f03f875f467ca952695b8367c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "new model\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 2,575\n",
      "Trainable params: 2,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021FEA1E6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "start learning player 1\n",
      "data length: 10\n",
      "planning number: 1 loss 899.9154052734375\n",
      "planning number: 2 loss 899.7967529296875\n",
      "planning number: 3 loss 899.6636962890625\n",
      "planning number: 4 loss 899.4597778320312\n",
      "planning number: 5 loss 899.1337890625\n",
      "planning number: 6 loss 898.611328125\n",
      "planning number: 7 loss 897.7822265625\n",
      "planning number: 8 loss 896.4583129882812\n",
      "planning number: 9 loss 894.3070068359375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-2ea5c4d98d01>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0mgame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Desktop\\Master\\Aktuelle Themen\\infm2100_2021\\build\\Game.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mcurrent_player\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplayers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mturn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent_player\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m                 \u001B[0mstate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mover\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Master\\Aktuelle Themen\\infm2100_2021\\build\\Game.py\u001B[0m in \u001B[0;36mturn\u001B[1;34m(self, player, board)\u001B[0m\n\u001B[0;32m     49\u001B[0m         \u001B[0mis_valid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_valid\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m             \u001B[0mplayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgive_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mResult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mINVALID_MOVE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m             \u001B[0mpos\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_move\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mboard\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m             \u001B[0mis_valid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Master\\Aktuelle Themen\\infm2100_2021\\build\\player\\QPlayer.py\u001B[0m in \u001B[0;36mgive_result\u001B[1;34m(self, result)\u001B[0m\n\u001B[0;32m     81\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstats\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mincr_draw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate_q_lerner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprev_action\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Master\\Aktuelle Themen\\infm2100_2021\\build\\player\\QPlayer.py\u001B[0m in \u001B[0;36mupdate_q_lerner\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     96\u001B[0m         \"\"\"\n\u001B[0;32m     97\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprev_action\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mq_learner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprev_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprev_action\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprev_reward\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     99\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-443c98f8202c>\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, prev_state, state, prev_move, reward)\u001B[0m\n\u001B[0;32m     33\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcount_memory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m             \u001B[1;31m# Offline training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlearn_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m             \u001B[1;31m# Online training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m             \u001B[1;31m#self.learn(self.prev_state, self.prev_move, state,  -1, self.reward)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-c74e70c010f0>\u001B[0m in \u001B[0;36mlearn_batch\u001B[1;34m(self, memory)\u001B[0m\n\u001B[0;32m    164\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0.02\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m             \u001B[1;31m# tic()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 166\u001B[1;33m             \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmemory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    167\u001B[0m             \u001B[1;31m# toc()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-c74e70c010f0>\u001B[0m in \u001B[0;36mcreate_targets\u001B[1;34m(self, memory)\u001B[0m\n\u001B[0;32m    186\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mv_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmemory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m             \u001B[1;33m[\u001B[0m\u001B[0mprev_state_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprev_move_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward_\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mv_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 188\u001B[1;33m             \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprev_state_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprev_move_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    189\u001B[0m             \u001B[0my_train_\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcount_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    190\u001B[0m             \u001B[0mcount_\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-c74e70c010f0>\u001B[0m in \u001B[0;36mcalc_target\u001B[1;34m(self, prev_state, prev_move, state, reward)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmove\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 85\u001B[1;33m             \u001B[0mv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmove\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     86\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mreward\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-c74e70c010f0>\u001B[0m in \u001B[0;36mcalc_value\u001B[1;34m(self, state, move)\u001B[0m\n\u001B[0;32m     64\u001B[0m         \"\"\"\n\u001B[0;32m     65\u001B[0m         \u001B[0mtensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmove\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m         \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m         \u001B[1;31m# K.backend.clear_session()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1596\u001B[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001B[0;32m   1597\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1598\u001B[1;33m       data_handler = data_adapter.DataHandler(\n\u001B[0m\u001B[0;32m   1599\u001B[0m           \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1600\u001B[0m           \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1099\u001B[0m     \u001B[0madapter_cls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mselect_data_adapter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1100\u001B[1;33m     self._adapter = adapter_cls(\n\u001B[0m\u001B[0;32m   1101\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m     \u001B[1;31m# trigger the next permutation. On the other hand, too many simultaneous\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    318\u001B[0m     \u001B[1;31m# shuffles can contend on a hardware level and degrade all performance.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 319\u001B[1;33m     \u001B[0mindices_dataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindices_dataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpermutation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprefetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    320\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mslice_batch_indices\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36mmap\u001B[1;34m(self, map_func, num_parallel_calls, deterministic)\u001B[0m\n\u001B[0;32m   1803\u001B[0m     \"\"\"\n\u001B[0;32m   1804\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnum_parallel_calls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1805\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mMapDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_func\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpreserve_cardinality\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1806\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1807\u001B[0m       return ParallelMapDataset(\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001B[0m\n\u001B[0;32m   4201\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_use_inter_op_parallelism\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0muse_inter_op_parallelism\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4202\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_preserve_cardinality\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreserve_cardinality\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4203\u001B[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001B[0m\u001B[0;32m   4204\u001B[0m         \u001B[0mmap_func\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4205\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_transformation_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m   3523\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mtracking\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresource_tracker_scope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresource_tracker\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3524\u001B[0m         \u001B[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3525\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwrapper_fn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3526\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0madd_to_graph\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3527\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_to_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mget_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3049\u001B[0m       \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0minputs\u001B[0m \u001B[0mto\u001B[0m \u001B[0mspecialize\u001B[0m \u001B[0mon\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3050\u001B[0m     \"\"\"\n\u001B[1;32m-> 3051\u001B[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001B[0m\u001B[0;32m   3052\u001B[0m         *args, **kwargs)\n\u001B[0;32m   3053\u001B[0m     \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_garbage_collector\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelease\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3017\u001B[0m       \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3018\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3019\u001B[1;33m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3020\u001B[0m       \u001B[0mseen_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3021\u001B[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3359\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m           \u001B[0mgraph_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3363\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3194\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3195\u001B[0m     graph_function = ConcreteFunction(\n\u001B[1;32m-> 3196\u001B[1;33m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[0;32m   3197\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3198\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    989\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 990\u001B[1;33m       \u001B[0mfunc_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    991\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    992\u001B[0m       \u001B[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36mwrapper_fn\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m   3516\u001B[0m           attributes=defun_kwargs)\n\u001B[0;32m   3517\u001B[0m       \u001B[1;32mdef\u001B[0m \u001B[0mwrapper_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=missing-docstring\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3518\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_wrapper_helper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3519\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstructure\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_tensor_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output_structure\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3520\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36m_wrapper_helper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m   3451\u001B[0m         \u001B[0mnested_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnested_args\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3452\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3453\u001B[1;33m       \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mautograph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtf_convert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mnested_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3454\u001B[0m       \u001B[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3455\u001B[0m       \u001B[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    665\u001B[0m       \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    666\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconversion_ctx\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 667\u001B[1;33m           \u001B[1;32mreturn\u001B[0m \u001B[0mconverted_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    668\u001B[0m       \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    669\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'ag_error_metadata'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001B[0m in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muser_requested\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconversion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_allowlisted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 396\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_call_unconverted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m   \u001B[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001B[0m in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    476\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    477\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 478\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    479\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36mpermutation\u001B[1;34m(_)\u001B[0m\n\u001B[0;32m    308\u001B[0m       \u001B[1;31m# than reusing the same range Tensor. (presumably because of buffer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m       \u001B[1;31m# forwarding.)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 310\u001B[1;33m       \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    311\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"batch\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m         \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom_shuffle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 201\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    202\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36mrange\u001B[1;34m(start, limit, delta, dtype, name)\u001B[0m\n\u001B[0;32m   1854\u001B[0m       \u001B[0mstart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"start\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1855\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlimit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1856\u001B[1;33m       \u001B[0mlimit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlimit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"limit\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1857\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1858\u001B[0m       \u001B[0mdelta\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"delta\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001B[0m in \u001B[0;36mwrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrace_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mtrace_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[0;32m   1538\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1539\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1540\u001B[1;33m       \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1541\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1542\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001B[0m in \u001B[0;36m_default_conversion_function\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_default_conversion_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m   \u001B[1;32mdel\u001B[0m \u001B[0mas_ref\u001B[0m  \u001B[1;31m# Unused.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[1;34m(value, dtype, shape, name)\u001B[0m\n\u001B[0;32m    262\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0ma\u001B[0m \u001B[0msymbolic\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    263\u001B[0m   \"\"\"\n\u001B[1;32m--> 264\u001B[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0m\u001B[0;32m    265\u001B[0m                         allow_broadcast=True)\n\u001B[0;32m    266\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[0;32m    284\u001B[0m   \u001B[0mdtype_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mattr_value_pb2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAttrValue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtensor_value\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    285\u001B[0m   \u001B[0mattrs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"value\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtensor_value\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"dtype\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdtype_value\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 286\u001B[1;33m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    287\u001B[0m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001B[0;32m    288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m    588\u001B[0m       \u001B[0minp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcapture\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    589\u001B[0m       \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 590\u001B[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    591\u001B[0m         \u001B[0mop_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_types\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m         compute_device)\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_op_internal\u001B[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001B[0m\n\u001B[0;32m   3526\u001B[0m     \u001B[1;31m# Session.run call cannot occur between creating and mutating the op.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3527\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mutation_lock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3528\u001B[1;33m       ret = Operation(\n\u001B[0m\u001B[0;32m   3529\u001B[0m           \u001B[0mnode_def\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3530\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001B[0m\n\u001B[0;32m   2013\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mop_def\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2014\u001B[0m         \u001B[0mop_def\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_graph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_op_def\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2015\u001B[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001B[0m\u001B[0;32m   2016\u001B[0m                                 control_input_ops, op_def)\n\u001B[0;32m   2017\u001B[0m       \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnode_def\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001B[0m\n\u001B[0;32m   1851\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1852\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m     \u001B[0mc_op\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpywrap_tf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_FinishOperation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_desc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1854\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInvalidArgumentError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1855\u001B[0m     \u001B[1;31m# Convert to ValueError for backwards compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for j in trange(100):\n",
    "\n",
    "    player1 = QPlayer('x', QNNLearner(model=TicTacToeModel(1)))\n",
    "    player2 = QPlayer('o', QNNLearner(model=TicTacToeModel(-1)))\n",
    "    players = [player1, player2]\n",
    "\n",
    "    game = Game(players)\n",
    "\n",
    "    for i in range(1000):\n",
    "        game.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}